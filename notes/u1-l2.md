# Unit 1: Optimization, Dynamic Programming, And Graphs

# Lecture 2: Decision Trees And Dynamic Programming

## 1.3 Brute Force Algorithms

---
### Search Tree Implementation
---

- the tree is built top down starting with the root
- the first element is selected from the still-to-be-considered items
    - if there is room for that item in the knapsack, a node is constructed that reflects the consequences of choosing to take that item
        - by convention, we draw that as the **left child**
    - we also explore the consequences of not taking that item -- the **right child**
- the process is then applied **recursively** to non-leaf children
    - because each edge of this tree represents a decision to take or not take an item
- finally, choose a node with the highest value that meets constraints

- called **decision trees** or **search trees**

---
### A Search Tree Enumerates Possibilities
---

- we have:
    - knapsack, beer, pizza, burger

- say we choose the beer first, a point from where we can choose to take the pizza or the burger (left-first, depth-first enumeration)
    - left-first, depth first: go all the way to the bottom of the tree this way, then traverse and check each possibility on the way back up
- once we're done, we've explored all possibilities; we can then look at what the value and calories of each are
    - if there are too many calories then that node is not eligible
    - choose the eligible node that has the highest value

---
### Computational Complexity
---

- time based on number of nodes generated
- number of levels is number of items to choose from
- number of nodes at that level `i` is `2^i`
- so, if there are `n` items the number of nodes is the sum from 0 to n of 2^`i`
    - *O(2^(`n`+1))*
        - exponential
- an obvious optimization: don't explore parts of the tree that violate constraint (e.g., too many calories)
    - doesn't change complexity, unfortunately

---
### Header For Decision Tree Implementation
---

```python
def maxVal(toConsider, avail):
    """
    assumes toConsider a list of items, avail a weight

    returns tuple of the total value of a solution to a 0/1 knapsack problem
    and the items of that solution
    """
```
- `toConsider`: those items that nodes higher up in the tree (corresponding to earlier calls in the recursive stack) have not yet considered
- `avail`: the amount of space still available
- we're going to be calling this recursively, so these things are going to be changing

---
### Body Of `maxVal`
---

```python
def maxVal(toConsider, avail):
    """
    assumes toConsider a list of items, avail a weight

    returns tuple of the total value of a solutin to a 0/1 knapsack problem
    and the items of that solution
    """
    if toConsider == [] or avail == 0:
        result = (0, ())
    elif toConsider[0].getUnits() > avail:
        # Explore right branch only
        result = maxVal(toConsider[1:], avail)
    else:
        nextItem = toConsider[0]
        # Explore left branch

        withVal, withToTake = maxVal(toConsider[1:], avail - nextItem.getUnits())
        withVal += nextItem.getValue()

        # Explore right branch
        withoutVal, withoutToTake = maxVal(toConsider[1:], avail)

        # Explore better branch
        if withVal > withoutVal:
            result = (withVal, withToTake + (nextItem,))
        else:
            result = (withoutVal, withoutToTake)
    return result
```
- does not actually build search tree
    - local variable `result` records best solution found so far

---
### Trying On Example From Lecture 1
---

- recall food menu
- with calorie budget of 750, choose an optimal set of foods from the menu

- brute force does indeed find a better solution, but the better solution is one we might not like
    - `pizza`, `cola`, `beer`, and `wine` is the best for the constraints defined, but maybe as humans we don't like the fact that there are three drinks to one item of solid food
        - how could we have avoided this?
            - defining the problem differently and layered on a constraint about the relative balance, say, of food and drink

---
### Search Tree Worked Great
---

- gave us a better answer
- finished quickly
- but 2^8 is not a large number
    - we should look at what happens when we have a more extensive menu to choose from

---

## 1.4 Recursive Fibonacci

---
### Code To Try Larger Examples
---

```python
import random

def buildLargeMenu(numItems, maxVal, maxCost):
    items = []
    for i in range(numItems):
        items.append(Food(str(i), random.randint(1, maxVal), random.randint(1, maxCost)))
    return items

for numItems in (5, 10, 15, 20, 25, 30, 35, 40, 45):
    items = buildLargeMenu(numItems, 90, 250)
    textMaxVal(items, 750, False)
```

---
### Is It Hopeless?
---

- in theory, yes
- in practice, no!
    - dynamic programming to the rescue

---
### Dynamic Programming?
---

Sometimes, a name is just a name.  

> "The 1950s were not good years for mathematical research... I felt I had to do something to shield Wilson and the Air Force from the fact that I was really doing mathematics... What title, what name, could I choose?  ... It's impossible to use the word dynamic in a perjorative sense.  Try thinking of some combination that will possibly give it a perjorative meaning.  It's impossible.  Thus, I thought dynamic programming was a good name.  It was something not even a Congressman could object to.  So I used it as an umbrella for my activities."  
--Richard Bellman  

---
### Recursive Implementation Of Fibonacci
---

```python
def fib(n):
    if n == 0 or n == 1:
        return 1
    else:
        return fib(n-1) + fib(n-2)

fib(120)
```
- why does this tiny block of code take *so* long to run?
    - clearly, must be the number of times the function calls itself

---
### Clearly A Bad Idea To Repeat Work
---

- trade time for space
- create a table to record what we've done
    - before computing `fib(x)`, check if value of `fib(x)` already stored in the table
        - if so, look it up
        - in not, compute it and then add it to table
    - called **memoization**

---
### Using A Memo To Compute Fibonacci
---

```python
def fastFib(n, memo={}):
    """
        Assumes n is an int >= 0, memo used only by recursive calls
        Returns Fibonacci of n
    """
    if n == 0 or n == 1:
        return 1
    try:
        return memo[n]
    except KeyError:
        result = fastFib(n-1, memo) + fastFib(n-2, memo)
        memo[n] = result
        return result
```
- this code is an ***immense*** improvement in runtime efficiency

---
### When Does It Work
---

- **optimal substructure**
    - a globally optimal solution can be found by combining optimal solutions to local subproblems
        - for `x>1`, `fib(x)` = `fib(x-1) + fib(x-2)`

- **overlapping subproblems**
    - finding an optimal solution involves solving the same problem multiple times
        - compute `fib(x)` or many times

---
### What About 0/1 Knapsack Problem?
---

- do these conditions hold?

---

## 1.5 Dynamic Programming

---
### Search Tree
---

- recall a search tree built from menu choices including beer, pizza, and a burger
- there's clearly **optimal substructure**
    - each parent node combines the solutions reached by its children to derive an optimal solution for the subtree rooted at that parent
        - so we could start from the top, for example, and say the right answer to what to do here is going to be the better of the two answers
- what about **overlapping subproblems**?
    - each node is solving a different problem
        - no two nodes have the same contents of the knapsack and the same two food items to choose from
            - so we could run a dynamic programming algorithm on this, but it wouldn't do anything to speed it up

---
### Need Not Have Copies Of Items
---

| Item | Value | Calories |
| --- | --- | --- |
| a | 6 | 3 |
| b | 7 | 3 |
| c | 8 | 2 |
| d | 9 | 5 |

---
### What Problem Is Solved At Each Node?
---

- given remaining weight, maximize value by choosing among remaining items
- set of previously chosen items, or even value of that set, doesn't matter!

---
### Modify `maxVal` To Use A Memo
---

- add memo as third argument
```python
def fastMaxVal(toConsider, avail, memo={}):
```
- key of memo is a tuple
    - (items left to be considered, available weight)
    - items left to be considered represented by `len(toConsider)`
- first thing body of function does is check whether the optimal choice of items given the available weight is already in the memo
- last thing the body of the function does is update the memo

```python
def fastMaxVal(toConsider, avail, memo={}):
    """
        Assumes toConsider a list of subjects, avail a weight
         memo supplied by recursive calls
        Returns a tuple of the total value of a solution to the
         0/1 knapsack problem and the subjects of that solution
    """
    if (len(toConsider), avail) in memo:
        result = memo[(len(toConsider), avail)]
    elif toConsider == [] or avail == 0:
        result = (0, ())
    elif toConsider[0].getCost > avail:
        # Explore right branch only
        result = fastMaxVal(toConsider[1:], avail, memo)
    else:
        nextItem = toConsider[0]
        # Explore left branch
        withVal, withToTake = fastMaxVal(toConsider[1:], avail - nextItem.getCost(), memo)
        withVal += nextItem.getValue()

        # Explore right branch
        withoutVal, withoutToTake = fastMaxVal(toConsider[1:], avail, memo)

        # Choose better branch
        if withVal > withoutVal:
            result = (withVal, withToTake + (nextItem,))
        else:
            result = (withoutVal, withoutToTake)

    memo[(len(toConsider), avail)] = result
    return result

def testMaxVal(foods, maxUnits, algorithm, printItems=True):
    print('Menu contains', len(foods), 'items')
    print('Use search tree to allocate', maxUnits, 'calories')

    val, taken = algorithm(foods, maxUnit)
    if printItems:
        print('Total value of items taken =', val)
        for item in taken:
            print('   ', item)
```

---
### Performance
---

| `len(items)` | `2**len(items)` | Number of calls |
| --- | --- | --- |
| 2 | 4 | 7 |
| 4 | 16 | 25 |
| 8 | 256 | 427 |
| 16 | 65,536 | 5,191 |
| 32 | 4,294,967,296 | 22,701 |
| 64 | 18,446,744,073,709,551,616 | 42,569 |
| 128 | Big | 83,319 |
| 256 | Really big | 176,614 |
| 512 | Ridiculously big | 351,230 |
| 1024 | Absurdly big | 703,802 |

- now, this growth may be hard to quantify for ways we'll talk about shortly, but it's clearly an enormous improvement over exponential

---
### How Can This Be?
---

- problem is exponential
- have we overturned the laws of the universe?
- is dynamic programming a miracle?
    - no, but computational complexity can be subtle

- running time of `fastMaxVal` is governed by number of distinct pairs, <`toConsider`, `avail`>
    - number of possible values of `toConsider` bounded by `len(items)`
    - possible values of `avail` a bit harder to characterize
        - bounded by number of distinct sums of weights
- psuedo-polynomial algorithm
    - most of the time runs in polynomial time, but worst case, when there are not overlapping subproblems, it reverts back to exponential time

---
### Summary Of Lectures 1-2
---

- many problems of practical importance can be formulated as **optimization problems**
- **greedy algorithms** often provide adequate (though not necessarily optimal) solutions
- finding an optimal solution is usually **exponentially hard**
- but, **dynamic programming** often yields good performance for a subclass of optimization problems
    - those with optimal substructure and overlapping subproblems
        - solution is always correct
        - fast under the right circumstances
---